import geminiClient from '../utils/gemini-client.js';
import audioUtils from '../utils/audio-utils.js';
import fs from 'fs';
import path from 'path';

class MusicStoryboardGeneratorAgent {
  /**
   * åˆå¹¶éŸ³ä¹åˆ†æã€è§†è§‰æ¦‚å¿µç”Ÿæˆå’Œåˆ†é•œè„šæœ¬ç”Ÿæˆ
   * ç›´æ¥åŸºäºéŸ³ä¹ç”Ÿæˆåˆ†é•œè„šæœ¬ï¼Œè¯†åˆ«å¡ç‚¹ï¼Œè§†é¢‘é•¿åº¦ç­‰äºéŸ³ä¹é•¿åº¦
   */
  async generate(audioPath, lyricsText = null) {
    console.log('ğŸ¬ Agent 1: éŸ³ä¹åˆ†æä¸åˆ†é•œç”Ÿæˆå™¨ - å¼€å§‹ç”Ÿæˆ...');
    
    try {
      // è·å–éŸ³é¢‘æ—¶é•¿
      let audioInfo;
      try {
        audioInfo = await audioUtils.getAudioInfo(audioPath);
        console.log(`   ğŸ“Š éŸ³é¢‘æ—¶é•¿: ${audioInfo.duration.toFixed(2)} ç§’`);
      } catch (error) {
        console.warn('   âš ï¸  æ— æ³•è·å–éŸ³é¢‘ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼');
        audioInfo = { duration: 30 };
      }

      const videoDuration = audioInfo.duration || 30;
      
      // æ„å»ºç»¼åˆæç¤ºè¯ï¼šéŸ³ä¹åˆ†æ + è§†è§‰æ¦‚å¿µ + åˆ†é•œè„šæœ¬
      let prompt = `You are a professional music video producer. Please carefully listen to and analyze this music, then generate a complete storyboard directly.

`;

      if (lyricsText) {
        prompt += `Lyrics:
${lyricsText}

`;
      }

      prompt += `**Task Requirements:**
1. Analyze the music's emotion, rhythm, theme, structure, and climax
2. Identify beat points in the music (rhythm changes, beat accents, climax, etc.)
3. Generate visual style and color scheme based on music analysis
4. Generate a complete storyboard directly. The total video duration must be exactly ${videoDuration.toFixed(2)} seconds

**Music Analysis Requirements:**
Please analyze the following:
- Emotion Recognition: Primary emotion, intensity (0-10 scale), secondary emotions
- Rhythm Analysis: Estimated BPM, rhythm characteristics, time positions of rhythm changes (in seconds)
- Theme Extraction: Main theme, keyword list (at least 5 keywords)
- Structure Analysis: Identify verses, choruses, bridges, interludes, etc., and their time positions
- Climax Recognition: Time when climax occurs (in seconds), intensity (0-10 scale)
- Beat Point Recognition: Identify all important musical beat points (beat accents, rhythm changes, emotional transitions, etc.) and their time positions

**Visual Concept Requirements:**
Based on music analysis, generate:
- Visual Style: Specific visual style (e.g., cyberpunk, retro, minimalist, abstract, natural, cinematic, etc.)
- Color Scheme: Primary colors, secondary colors, color mood
- Visual Element Suggestions: Recommended visual elements (e.g., particles, light effects, abstract graphics, etc.)

**Storyboard Requirements:**
1. Total video duration must be exactly ${videoDuration.toFixed(2)} seconds
2. **Each shot is fixed at 8 seconds** (the last shot may be less than 8 seconds, based on total video duration)
3. Shot count calculation: ${Math.ceil(videoDuration / 8)} shots are needed
4. Each shot must include:
   - Timecode (precise to 2 decimal places, each shot fixed at 8 seconds, format: 0.00-8.00, 8.00-16.00, ...)
   - Framing (wide shot/medium shot/close-up/extreme close-up)
   - Composition description
   - Lighting description (cool tone/warm tone/high contrast, etc.)
   - Camera movement (push/pull/pan/track/static)
   - Action description
   - Sync point with music (must mark beat point positions)
   - Transition type (fade in/fade out/cut/wipe, etc.)
   - Detailed prompt for image/video generation
5. **Key Requirements**:
   - Each shot must be strictly fixed at 8 seconds (except the last shot)
   - Shot 1: 0.00-8.00 seconds
   - Shot 2: 8.00-16.00 seconds
   - Shot 3: 16.00-24.00 seconds
   - ...and so on
   - The last shot's end time must be exactly ${videoDuration.toFixed(2)} seconds
   - Visual style and colors must be consistent with music emotion and theme

Please return in JSON format, ensuring correct format:
{
  "musicAnalysis": {
    "emotion": {
      "primary": "primary emotion",
      "intensity": intensity score (number),
      "secondary": ["secondary emotion 1", "secondary emotion 2"]
    },
    "rhythm": {
      "bpm": BPM value (number),
      "character": "rhythm characteristics description",
      "changes": [time positions of rhythm changes (seconds, numbers)],
      "beats": [time positions of beat accents (seconds, numbers)]
    },
    "theme": {
      "keywords": ["keyword 1", "keyword 2", "keyword 3", "keyword 4", "keyword 5"],
      "mainTheme": "main theme"
    },
    "structure": [
      {
        "type": "section type (verse/chorus/bridge/interlude)",
        "startTime": start time (seconds, number),
        "endTime": end time (seconds, number),
        "description": "section description"
      }
    ],
    "climax": {
      "time": climax time (seconds, number),
      "intensity": intensity (number)
    },
    "beatPoints": [time positions of all beat points (seconds, numbers)]
  },
  "visualConcept": {
    "style": {
      "name": "style name",
      "description": "detailed style description",
      "references": "style reference notes"
    },
    "colorPalette": {
      "primary": ["primary color 1", "primary color 2"],
      "secondary": ["secondary color 1", "secondary color 2"],
      "mood": "color mood description"
    },
    "visualElements": ["recommended element 1", "recommended element 2"]
  },
  "storyboard": {
    "shots": [
      {
        "shotNumber": shot number (number),
        "timeRange": "0.00-8.00" (each shot fixed at 8 seconds, format: 0.00-8.00, 8.00-16.00, 16.00-24.00...),
        "startTime": 0.00 (number, precise to 2 decimal places, each shot spaced 8 seconds apart),
        "endTime": 8.00 (number, precise to 2 decimal places, each shot fixed at 8 seconds, except the last shot),
        "framing": "framing (wide shot/medium shot/close-up/extreme close-up)",
        "composition": "composition description",
        "lighting": "lighting description (cool tone/warm tone/high contrast, etc.)",
        "movement": "camera movement (push/pull/pan/track/static)",
        "action": "action description",
        "syncPoint": "sync point description with music (must mark beat point)",
        "beatPoint": beat point time (seconds, number, if any),
        "transition": {
          "type": "transition type (fade in/fade out/cut/wipe, etc.)",
          "duration": transition duration (seconds, number)
        },
        "prompt": "detailed prompt for image/video generation"
      }
    ],
    "totalDuration": ${videoDuration.toFixed(2)} (number, must be exactly equal to audio duration),
    "notes": "storyboard notes and considerations"
  }
}`;

      // å°è¯•ä½¿ç”¨ Gemini ç›´æ¥åˆ†æéŸ³é¢‘æ–‡ä»¶
      let result;
      try {
        console.log('   ğŸ“¡ ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶åˆ° Gemini API...');
        result = await geminiClient.generateJSONWithAudio(prompt, audioPath);
        console.log('   âœ… éŸ³ä¹åˆ†æä¸åˆ†é•œç”Ÿæˆå®Œæˆ');
      } catch (error) {
        console.warn('   âš ï¸  éŸ³é¢‘æ–‡ä»¶åˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ–‡æœ¬æ¨¡å¼åˆ†æ');
        // å¦‚æœéŸ³é¢‘åˆ†æå¤±è´¥ï¼Œå›é€€åˆ°åŸºäºæ­Œè¯å’Œæ–‡ä»¶åçš„æ–‡æœ¬åˆ†æ
        const fileName = path.basename(audioPath, path.extname(audioPath));
        const fallbackPrompt = `You are a professional music video producer. Please analyze the following music and generate a storyboard:

${lyricsText ? `Lyrics:\n${lyricsText}\n\n` : ''}Filename: ${fileName}

${prompt}`;
        result = await geminiClient.generateJSON(fallbackPrompt);
      }
      
      // è§£æç»“æœ
      let parsedResult;
      if (result.raw) {
        try {
          parsedResult = typeof result.raw === 'string' ? JSON.parse(result.raw) : result.raw;
        } catch (e) {
          // å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æå– JSON
          const jsonMatch = result.raw.match(/\{[\s\S]*\}/);
          if (jsonMatch) {
            parsedResult = JSON.parse(jsonMatch[0]);
          } else {
            throw new Error('æ— æ³•è§£æ JSON ç»“æœ');
          }
        }
      } else {
        parsedResult = result;
      }

      // éªŒè¯å’Œä¿®æ­£åˆ†é•œè„šæœ¬çš„æ—¶é—´ - å¼ºåˆ¶æ¯ä¸ªé•œå¤´8ç§’
      if (parsedResult.storyboard && parsedResult.storyboard.shots) {
        const shots = parsedResult.storyboard.shots;
        const SHOT_DURATION = 8.0; // å›ºå®šæ¯ä¸ªé•œå¤´8ç§’
        
        // è®¡ç®—éœ€è¦çš„é•œå¤´æ•°é‡
        const requiredShots = Math.ceil(videoDuration / SHOT_DURATION);
        
        // å¦‚æœAIç”Ÿæˆçš„é•œå¤´æ•°é‡ä¸å¯¹ï¼Œé‡æ–°ç”Ÿæˆé•œå¤´åˆ—è¡¨
        if (shots.length !== requiredShots) {
          console.log(`   âš ï¸  AIç”Ÿæˆäº† ${shots.length} ä¸ªé•œå¤´ï¼Œéœ€è¦ ${requiredShots} ä¸ªé•œå¤´ï¼Œæ­£åœ¨ä¿®æ­£...`);
          
          // é‡æ–°æ„å»ºé•œå¤´åˆ—è¡¨ï¼Œæ¯ä¸ªé•œå¤´å›ºå®š8ç§’
          const newShots = [];
          for (let i = 0; i < requiredShots; i++) {
            const startTime = i * SHOT_DURATION;
            const endTime = i === requiredShots - 1 
              ? videoDuration  // æœ€åä¸€ä¸ªé•œå¤´ç»“æŸåœ¨è§†é¢‘æ€»æ—¶é•¿
              : startTime + SHOT_DURATION;
            
            // å¦‚æœåŸé•œå¤´å­˜åœ¨ï¼Œä¿ç•™å…¶å†…å®¹ï¼Œåªæ›´æ–°æ—¶é—´
            const originalShot = shots[i] || {};
            newShots.push({
              shotNumber: i + 1,
              timeRange: `${startTime.toFixed(2)}-${endTime.toFixed(2)}`,
              startTime: startTime,
              endTime: endTime,
              framing: originalShot.framing || 'ä¸­æ™¯',
              composition: originalShot.composition || 'é»˜è®¤æ„å›¾',
              lighting: originalShot.lighting || 'è‡ªç„¶å…‰',
              movement: originalShot.movement || 'é™æ­¢',
              action: originalShot.action || 'ç”»é¢åŠ¨ä½œ',
              syncPoint: originalShot.syncPoint || `ç¬¬${i + 1}ä¸ª8ç§’æ®µè½`,
              beatPoint: originalShot.beatPoint || null,
              transition: originalShot.transition || { type: 'åˆ‡å…¥', duration: 0.5 },
              prompt: originalShot.prompt || `ç¬¬${i + 1}ä¸ªé•œå¤´çš„è§†è§‰å†…å®¹`,
            });
          }
          parsedResult.storyboard.shots = newShots;
        } else {
          // å¦‚æœæ•°é‡æ­£ç¡®ï¼Œå¼ºåˆ¶ä¿®æ­£æ¯ä¸ªé•œå¤´çš„æ—¶é—´ä¸º8ç§’
          shots.forEach((shot, index) => {
            const startTime = index * SHOT_DURATION;
            const endTime = index === shots.length - 1 
              ? videoDuration  // æœ€åä¸€ä¸ªé•œå¤´ç»“æŸåœ¨è§†é¢‘æ€»æ—¶é•¿
              : startTime + SHOT_DURATION;
            
            shot.startTime = startTime;
            shot.endTime = endTime;
            shot.timeRange = `${startTime.toFixed(2)}-${endTime.toFixed(2)}`;
            shot.shotNumber = index + 1;
          });
        }
        
        parsedResult.storyboard.totalDuration = videoDuration;
        console.log(`   âœ… å·²ä¿®æ­£ä¸º ${parsedResult.storyboard.shots.length} ä¸ªé•œå¤´ï¼Œæ¯ä¸ªé•œå¤´å›ºå®š8ç§’`);
      }

      // å°è¯•è·å–éŸ³é¢‘åŸºæœ¬ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
      let audioInfoDetail = null;
      let bpmInfo = null;
      try {
        audioInfoDetail = await audioUtils.getAudioInfo(audioPath);
        bpmInfo = await audioUtils.detectBPM(audioPath);
      } catch (error) {
        // å¿½ç•¥éŸ³é¢‘ä¿¡æ¯è·å–é”™è¯¯
      }

      const finalResult = {
        audioInfo: audioInfoDetail || { duration: videoDuration, note: 'æœªè·å–éŸ³é¢‘æŠ€æœ¯ä¿¡æ¯' },
        bpmInfo: bpmInfo || { note: 'æœªæ£€æµ‹BPM' },
        musicAnalysis: parsedResult.musicAnalysis,
        visualConcept: parsedResult.visualConcept,
        storyboard: parsedResult.storyboard,
        timestamp: new Date().toISOString(),
        analysisMethod: 'gemini-direct',
      };

      console.log(`   âœ… ç”Ÿæˆå®Œæˆï¼š${parsedResult.storyboard?.shots?.length || 0} ä¸ªé•œå¤´`);
      return finalResult;
    } catch (error) {
      console.error('âŒ éŸ³ä¹åˆ†æä¸åˆ†é•œç”Ÿæˆå¤±è´¥:', error);
      throw error;
    }
  }
}

export default new MusicStoryboardGeneratorAgent();

