import fs from 'fs';
import path from 'path';
import config from '../../config/config.js';
import geminiClient from '../../utils/gemini-client.js';
import { batchConcurrent } from '../../utils/utils.js';
import characterLibrary from '../../utils/character-library.js';

const VIDEO_STYLE = 'Cocomelon style: bright vibrant colors, simple cute character design, smooth 3D animation, child-friendly visual style, rounded friendly characters, clear lines, simple backgrounds, educational and entertaining, playful and cheerful atmosphere, smooth motion from keyframe, high quality, consistent style and visual continuity';

class VideoGeneratorImageToVideoAgent {
  // åˆ›å»ºç´ ææ•°æ®ç»“æ„
  _createMaterial(keyframe) {
    const { shot, keyframeA } = keyframe;
    return {
      shotNumber: shot.shotNumber,
      timeRange: shot.timeRange,
      startTime: shot.startTime,
      endTime: shot.endTime,
      type: 'video',
      path: null,
      status: 'pending',
      shot,
      keyframeA
    };
  }

  // è·å–é•œå¤´æ—¶é—´æ®µå†…çš„æ‰€æœ‰å¡ç‚¹
  _getBeatPointsInRange(shot, musicAnalysis) {
    const beatPoints = musicAnalysis?.beatPoints || [];
    const shotStart = shot.startTime;
    const shotEnd = shot.endTime;
    
    return beatPoints.filter(beat => beat >= shotStart && beat < shotEnd);
  }

  // ä¸ºé•œå¤´é€‰æ‹©è§’è‰²
  _selectCharacterForShot(shot, storyboard) {
    // å¦‚æœ shot ä¸­å·²ç»æœ‰è§’è‰²ä¿¡æ¯ï¼Œä½¿ç”¨å®ƒ
    if (shot.characterName) {
      const character = characterLibrary.getCharacterByName(shot.characterName);
      if (character) {
        return character;
      }
    }
    
    // æ ¹æ®åœºæ™¯æè¿°æ™ºèƒ½é€‰æ‹©è§’è‰²
    const sceneDescription = shot.videoPrompt || shot.action || '';
    return characterLibrary.selectCharacterForScene(sceneDescription, shot.shotNumber);
  }

  // æ„å»ºè§†é¢‘æç¤ºè¯ï¼ˆå›¾ç”Ÿè§†é¢‘æ¨¡å¼ï¼‰
  _buildPrompt(shot, keyframeA, storyboard) {
    const duration = shot.endTime - shot.startTime;
    const beatPointsInRange = this._getBeatPointsInRange(shot, storyboard?.musicAnalysis);
    const rhythm = storyboard?.musicAnalysis?.rhythm;
    const concept = storyboard?.visualConcept?.visualConcept;
    
    // é€‰æ‹©è§’è‰²
    const character = this._selectCharacterForShot(shot, storyboard);
    
    // æ„å»ºèŠ‚æ‹åŒæ­¥æè¿°
    const buildBeatSyncDescription = () => {
      if (beatPointsInRange.length > 0) {
        const relativeBeatTimes = beatPointsInRange.map(beat => ({
          absolute: beat,
          relative: beat - shot.startTime
        }));
        const beatTimesAbsolute = relativeBeatTimes.map(b => `${b.absolute.toFixed(2)}s`).join(', ');
        const beatTimesRelative = relativeBeatTimes.map(b => `${b.relative.toFixed(2)}s`).join(', ');
        return [
          `Beat points in this segment (at music time): ${beatTimesAbsolute}`,
          `Beat points relative to segment start: ${beatTimesRelative}`,
          `At these beat points (${beatTimesRelative}), the action or camera movement MUST emphasize or change to match the music rhythm`,
          `The motion should accelerate, change direction, or create visual emphasis at these exact moments to sync with the music beats`,
          `Visual rhythm must match musical rhythm - action peaks should align with beat points`
        ];
      } else if (shot.beatPoint != null) {
        const relativeBeatTime = shot.beatPoint - shot.startTime;
        return [
          `Beat point at ${relativeBeatTime.toFixed(2)}s into this segment (music time: ${shot.beatPoint.toFixed(2)}s)`,
          `At this beat point (${relativeBeatTime.toFixed(2)}s), emphasize the action or change camera movement to sync with the music beat`
        ];
      }
      return [];
    };

    // å¿…é¡»ä½¿ç”¨ videoPromptï¼Œå¦‚æœæ²¡æœ‰åˆ™æŠ›å‡ºé”™è¯¯
    if (!shot.videoPrompt) {
      throw new Error(`é•œå¤´ ${shot.shotNumber} ç¼ºå°‘å¿…éœ€çš„ videoPrompt å­—æ®µ`);
    }
    
    const parts = [
      // ä½¿ç”¨æä¾›çš„ videoPrompt ä½œä¸ºåŸºç¡€ï¼ˆæè¿°åŠ¨æ€åŠ¨ä½œï¼‰
      shot.videoPrompt,
      
      // æ·»åŠ è§’è‰²ä¿¡æ¯ - ä¸¥æ ¼ç¦æ­¢ä¿®æ”¹è§’è‰²å¤–è§‚
      `CRITICAL CHARACTER CONSISTENCY: The character in this video must be "${character.name}". Character description: ${character.desc}`,
      `REFERENCE IMAGES PROVIDED:`,
      `- Keyframe image: Shows the scene and character in the initial state`,
      `- Character reference image: Shows the exact character design from the character library (${character.name})`,
      `- You MUST use BOTH reference images to ensure character consistency`,
      `- The character reference image shows the EXACT character design you must use - this is the authoritative source for character appearance`,
      `ABSOLUTELY FORBIDDEN during animation:`,
      `- DO NOT add, remove, or modify ANY character features (hair, accessories, clothing, backpacks, etc.)`,
      `- DO NOT change the character's colors, proportions, design elements, or visual details`,
      `- DO NOT modify facial features, body shape, or any appearance aspects`,
      `- DO NOT deviate from the character reference image in ANY way`,
      `MANDATORY REQUIREMENTS:`,
      `- The character's appearance must match the character reference image EXACTLY`,
      `- Use the character reference image as the authoritative source for character design`,
      `- The character's appearance, design, colors, accessories, clothing, and ALL details must remain EXACTLY the same as shown in the character reference image throughout the entire video`,
      `- Maintain the exact same character size, proportions, and visual appearance from start to end`,
      `- The character must look identical to the character reference image in every frame`,
      `- Copy the character design from the character reference image pixel-perfectly and maintain it throughout the animation`,
      
      // åœºæ™¯å¤§å°ä¸€è‡´æ€§
      `CRITICAL SCENE CONSISTENCY:`,
      `- Maintain the exact same scene scale, character size, and composition throughout the entire video`,
      `- The character's size relative to the scene must remain constant from start to end`,
      `- Keep the same camera distance and framing as shown in the keyframe image`,
      `- Do not zoom in or out - maintain consistent scene proportions`,
      `- The background and scene elements must maintain the same scale throughout`,
      
      // æ·»åŠ å¿…è¦çš„è¡¥å……ä¿¡æ¯
      `Generate video from keyframe image`,
      `Animate the scene smoothly based on the keyframe image`,
      `Maintain visual consistency: character appearance, scene scale, and composition must remain constant`,
      
      // æ—¶é—´å’ŒåŒæ­¥
      `duration: ${duration} seconds`,
      `time range: ${shot.timeRange} (music time: ${shot.startTime.toFixed(2)}s - ${shot.endTime.toFixed(2)}s)`,
      `CRITICAL: This video segment corresponds to music time ${shot.startTime.toFixed(2)}s - ${shot.endTime.toFixed(2)}s`,
      `The video motion, action, and rhythm MUST sync with the music beat and rhythm`,
      
      // èŠ‚æ‹åŒæ­¥æè¿°
      ...buildBeatSyncDescription(),
      
      // åŒæ­¥ç‚¹
      shot.syncPoint && `Sync point: ${shot.syncPoint}`,
      
      // éŸ³ä¹èŠ‚å¥ä¿¡æ¯
      rhythm?.bpm && `Music BPM: ${rhythm.bpm} - video motion tempo should match this beat rate`,
      rhythm?.bpm && `Beat interval: ${(60 / rhythm.bpm).toFixed(2)} seconds - motion should follow this rhythm`,
      rhythm?.character && `Music rhythm character: ${rhythm.character} - video motion should reflect this rhythm style`,
      
      // Cocomelon é£æ ¼
      VIDEO_STYLE,
      `The video motion rhythm must match the music rhythm throughout the entire segment`,
      `Animate the keyframe image smoothly, bringing the scene to life with natural motion that matches the music rhythm`
    ].filter(Boolean);
    
    return parts.join(', ');
  }

  // å‡†å¤‡å‚è€ƒå›¾åƒï¼ˆå…³é”®å¸§ + è§’è‰²åº“å‚è€ƒå›¾ç‰‡ï¼‰
  _prepareReferenceImages(keyframeA, shot, storyboard) {
    const referenceImages = [];
    
    // 1. æ·»åŠ å…³é”®å¸§å›¾åƒï¼ˆé¦–å¸§ï¼‰
    if (keyframeA?.path && fs.existsSync(keyframeA.path)) {
      referenceImages.push(keyframeA.path);
    }
    
    // 2. æ·»åŠ è§’è‰²åº“ä¸­çš„è§’è‰²å‚è€ƒå›¾ç‰‡
    const character = this._selectCharacterForShot(shot, storyboard);
    const characterImagePath = characterLibrary.getCharacterImagePath(character.name);
    
    if (characterImagePath && fs.existsSync(characterImagePath)) {
      referenceImages.push(characterImagePath);
      console.log(`    ğŸ­ æ·»åŠ è§’è‰²å‚è€ƒå›¾ç‰‡: ${character.name} (${path.basename(characterImagePath)})`);
    } else {
      console.warn(`    âš ï¸  è§’è‰² "${character.name}" çš„å›¾ç‰‡ä¸å­˜åœ¨: ${characterImagePath}`);
    }
    
    return referenceImages;
  }

  // ç”Ÿæˆå•ä¸ªè§†é¢‘ï¼ˆå›¾ç”Ÿè§†é¢‘æ¨¡å¼ï¼‰
  async _generateVideo(material, keyframeData) {
    const { shot, keyframeA } = material;
    
    console.log(`  ğŸ¬ é•œå¤´ ${shot.shotNumber}: ${shot.timeRange}ç§’ (å›¾ç”Ÿè§†é¢‘æ¨¡å¼)`);
    
    // æ‰“å°å¡ç‚¹ä¿¡æ¯
    const beatPointsInRange = this._getBeatPointsInRange(shot, keyframeData.storyboard?.musicAnalysis);
    if (beatPointsInRange.length > 0) {
      const relativeTimes = beatPointsInRange.map(b => `${(b - shot.startTime).toFixed(2)}s`).join(', ');
      console.log(`    ğŸµ å¡ç‚¹: ${beatPointsInRange.map(b => `${b.toFixed(2)}s`).join(', ')} (ç›¸å¯¹æ—¶é—´: ${relativeTimes})`);
    } else if (shot.beatPoint != null) {
      const relativeTime = shot.beatPoint - shot.startTime;
      console.log(`    ğŸµ å¡ç‚¹: ${shot.beatPoint.toFixed(2)}s (ç›¸å¯¹æ—¶é—´: ${relativeTime.toFixed(2)}s)`);
    }
    
    try {
      // æ£€æŸ¥å…³é”®å¸§æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      if (!keyframeA?.path || !fs.existsSync(keyframeA.path)) {
        throw new Error(`å…³é”®å¸§ä¸å­˜åœ¨: ${keyframeA?.path}`);
      }
      
      const videoPath = path.join(config.paths.temp, `shot_${shot.shotNumber}.mp4`);
      const videoPrompt = this._buildPrompt(shot, keyframeA, keyframeData.storyboard);
      
      // æ‰“å°å®Œæ•´æç¤ºè¯
      console.log(`\n    ğŸ“ å®Œæ•´æç¤ºè¯:`);
      console.log(`    ${videoPrompt}\n`);
      
      // å‡†å¤‡å‚è€ƒå›¾åƒï¼šå…³é”®å¸§ + è§’è‰²åº“å‚è€ƒå›¾ç‰‡
      const referenceImages = this._prepareReferenceImages(keyframeA, shot, keyframeData.storyboard);
      
      console.log(`    ğŸ“¸ ä½¿ç”¨ ${referenceImages.length} ä¸ªå‚è€ƒå›¾ç‰‡: å…³é”®å¸§ + è§’è‰²å‚è€ƒå›¾ç‰‡`);
      
      // è°ƒç”¨ Gemini Veo å›¾ç”Ÿè§†é¢‘ APIï¼ˆä¼ å…¥å…³é”®å¸§å’Œè§’è‰²å‚è€ƒå›¾ç‰‡ï¼‰
      await geminiClient.generateVideo(videoPrompt, videoPath, 'veo-3.1-generate-preview', referenceImages);
      
      material.path = videoPath;
      material.status = 'generated';
      material.prompt = videoPrompt;
      console.log(`    âœ… ç”Ÿæˆå®Œæˆ`);
    } catch (error) {
      console.error(`    âŒ ç”Ÿæˆå¤±è´¥: ${error.message}`);
      material.status = 'failed';
      material.error = error.message;
      
      // ä½¿ç”¨å…³é”®å¸§ A ä½œä¸ºåå¤‡
      if (keyframeA?.path) {
        material.path = keyframeA.path;
        material.type = 'image';
        material.status = 'keyframe_fallback';
        console.log(`    âš ï¸  ä½¿ç”¨å…³é”®å¸§ä½œä¸ºåå¤‡`);
      }
    }
  }

  // åŸºäºé¦–å¸§ç”Ÿæˆè§†é¢‘ï¼ˆå›¾ç”Ÿè§†é¢‘æ¨¡å¼ï¼‰
  async generate(keyframeData) {
    console.log('ğŸ¬ Agent 5 (å›¾ç”Ÿè§†é¢‘): è§†é¢‘ç”Ÿæˆå™¨ - å¼€å§‹ç”Ÿæˆ...');
    console.log('   æ¨¡å¼: ä½¿ç”¨é¦–å¸§å›¾åƒç”Ÿæˆè§†é¢‘ï¼ˆGemini Veo å›¾ç”Ÿè§†é¢‘æ¨¡å¼ï¼‰\n');
    
    try {
      const keyframes = keyframeData.keyframes || [];
      console.log(`ğŸ¬ åŸºäºé¦–å¸§å›¾åƒç”Ÿæˆ ${keyframes.length} ä¸ªè§†é¢‘ç‰‡æ®µ...\n`);
      
      const materials = keyframes.map(kf => this._createMaterial(kf));
      
      // ä½¿ç”¨å¹¶å‘æ§åˆ¶å·¥å…·å‡½æ•°
      await batchConcurrent(materials, 
        material => this._generateVideo(material, keyframeData),
        {
          concurrency: 5,
          startIndex: 0,
          onBatchStart: (batch, batchNum, total) => {
            console.log(`\nğŸ“¦ æ‰¹æ¬¡ ${batchNum}/${total}: é•œå¤´ ${batch[0].shotNumber}-${batch[batch.length - 1].shotNumber}`);
          },
          onBatchComplete: (batch, batchNum, total) => {
            const success = batch.filter(m => m.status === 'generated').length;
            console.log(`  âœ… æ‰¹æ¬¡å®Œæˆ: ${success}/${batch.length} ä¸ªè§†é¢‘\n`);
          }
        }
      );

      const successCount = materials.filter(m => m.status === 'generated').length;
      console.log(`âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ: ${successCount}/${materials.length} ä¸ªè§†é¢‘\n`);
      
      return {
        keyframeData,
        materials,
        timestamp: new Date().toISOString()
      };
    } catch (error) {
      console.error('âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥:', error);
      throw error;
    }
  }
}

export default new VideoGeneratorImageToVideoAgent();

